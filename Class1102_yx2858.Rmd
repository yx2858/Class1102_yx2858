---
title: "Class1102_yx2858"
author: "Yueyi Xu"
date: "2023-11-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

set.seed(1)

```

```{r}
sim_mean_sd = function(n, mu = 2, sigma = 3) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data |> 
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x)
    )
}
```


Let's see what this does

```{r}
sim_mean_sd(n_obs = 30)
```


Let's iterate to see how this works UNDER REPEATED SAMPLING!!!

```{r}
output = vector("list", 100)

for (i in 1:100) {
  output[[i]] = sim_mean_sd(30)
}

sim_results = bind_rows(output)

sim_results |>
  ggplot(aes(x = mu_hat)) + geom_density()

sim_results |>
  summarize(
    mu_hat = mean(mean),
    sd_hat = sd(mean)
  )
```


use a map function

```{r}
sim_results_df = 
  expand_grid(
    sample_size = c(30, 60, 120, 240),
    iter = 1:1000
  ) |> 
  mutate(
    estimate_df = map(sample_size, sim_mean_sd)
  ) |> 
  unnest(estimate_df)


sim_results_df |> 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)) |> 
  ggplot(aes(x = sample_size, y = mu_hat, fill = sample_size)) + 
  geom_boxplot()
```


## SLR

Goal is to write a function that stimulates data and then fits a regression; then repeat to look at the distribution of estimated coefficients.

```{r}
sim_regression = function(n, beta0 = 2, beta1 = 3) {
  
  sim_data = 
    tibble(
      x = rnorm(n, mean = 1, sd = 1),
      y = beta0 + beta1 * x + rnorm(n, 0, 1)
    )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}
```

```{r}
beta_0 = 2
beta_1 = 3

sim_data = 
    tibble(
      x = rnorm(n = 30, mean = 1, sd = 1),
      y = beta_0 + beta_1 * x + rnorm(30, 0, 1)
    )
ls_fit = lm(y ~ x, data = sim_data)
lsfit

sim_data |>
  ggplot(aes(x = x, y = y)) +
  geom_point()
```

let's wrap this in a function

```{r}
sim_slr = function(n_obs, beta_0 = 2, beta_1 = 3) {
  sim_data =
    tibble(
      x = rnorm(n = 30, mean = 1, sd = 1),
      y = beta_0 + beta_1 * x + rnorm(n_obs, mean = 0, sd = 1)
    )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}


sim_slr(n_obs = 30)
```


run this a whole bunch of times

```{r}
sim_results_df =
  expand_grid(
    sample_size = 30,
    iter = 1:1000) |>
  mutate(estimate_df = map(sample_size, sim_slr)) |>
  unnest(estimate_df)
```


Let's look at the results.

```{r}
sim_results_df |>
  summarize(
    mean_b0_hat = mean(beta0_hat),
    mean_b1_hat = mean(beta1_hat)
  )

sim_results_df |>
  ggplot(aes(x = beta0_hat)) +
  geom_histogram()

sim_results_df |>
  ggplot(aes(x = beta0_hat, y = beta1_hat)) +
  geom_point()
```


